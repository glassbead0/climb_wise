{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models import get_conn\n",
    "import geopandas as gpd\n",
    "import googlemaps\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "pd.set_option('display.expand_frame_repr', False) # display full data in terminal\n",
    "\n",
    "load_dotenv()\n",
    "engine, Session = get_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use acutal google maps API instead of just web scraping. Issues: I'm using the 'Title' of each pin, which didn't return an exact match for all locations. I manually edited ~20 locations in the CSV,\n",
    "# Adding extra keyworks to teh title (often a state), to get the goglemaps api to return the right result. I still have 4 rows that google couldn't match. Since some titles may return multiple\n",
    "# results this doesn't guarantee an exact match.\n",
    "\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "gmaps = googlemaps.Client(key=api_key)\n",
    "\n",
    "def get_lat_long(title):\n",
    "    # Geocode the place to get coordinates\n",
    "    geocode_result = gmaps.geocode(title)\n",
    "    if geocode_result:\n",
    "        lat = geocode_result[0]['geometry']['location']['lat']\n",
    "        lng = geocode_result[0]['geometry']['location']['lng']\n",
    "        return lat, lng\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def fetch_all_lat_long(df):\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "\n",
    "    for _, location in df.iterrows():\n",
    "        lat, lng = get_lat_long(location.title)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(lng)\n",
    "\n",
    "    df['latitude'] = latitudes\n",
    "    df['longitude'] = longitudes\n",
    "    return df\n",
    "\n",
    "# locations_df_raw = pd.read_csv('csv_files/2023_2024_Van_Trip.csv')\n",
    "locations_df_raw = pd.read_csv('csv_files/additional_van_stops.csv')\n",
    "locations_df_raw['notes'] = locations_df_raw['notes'].fillna(\"2023 2024 Van Trip\")\n",
    "locations_df_raw.drop(columns=['comment', 'url'], inplace=True)\n",
    "\n",
    "locations_df = fetch_all_lat_long(locations_df_raw)\n",
    "\n",
    "# There were ~4 locations that I couldnt get googleapi to return results for.\n",
    "locations_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to waypoints: we have now added lat/long/geom column\n",
    "\n",
    "gdf = gpd.GeoDataFrame(locations_df, geometry=gpd.points_from_xy(locations_df.longitude, locations_df.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "with Session() as session:\n",
    "    gdf.to_postgis(\n",
    "        name='waypoints',\n",
    "        con=engine,\n",
    "        if_exists='append'\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FAILED DUE TO GOOGLE RATE LIMITING!! SKIP TO NEXT CELL. leaving here for posterity\n",
    "# Googles exported CSV of places doesn't have Lat/Long, just a url for each location. Fetch each url, look at the rediurect URL, which embedds the Lat/Long\n",
    "\n",
    "# locations_df_raw = pd.read_csv('csv_files/2023_2024_Van_Trip.csv')\n",
    "# locations_df_raw['notes'] = locations_df['notes'].fillna(\"2023 2024 Van Trip\")\n",
    "\n",
    "# def populate_lat_long(df):\n",
    "#     latitudes = []\n",
    "#     longitudes = []\n",
    "\n",
    "#     for _, location in df.iterrows():\n",
    "#         redirected_url = get_redirect_url(location['url'])\n",
    "#         lat, long = extract_lat_long_from_redirect(redirected_url)\n",
    "#         latitudes.append(lat)\n",
    "#         longitudes.append(long)\n",
    "\n",
    "#     df['latitude'] = latitudes\n",
    "#     df['longitude'] = longitudes\n",
    "#     return df\n",
    "\n",
    "# def get_redirect_url(url):\n",
    "#     response = requests.get(url, timeout=10)\n",
    "#     response.raise_for_status()\n",
    "#     return response.url\n",
    "\n",
    "# def extract_lat_long_from_redirect(url):\n",
    "#     try:\n",
    "#         parsed_url = urlparse(url)\n",
    "#         # query_params = parse_qs(parsed_url.query)\n",
    "        \n",
    "#         # Look for `3d` and `4d` in the URL path\n",
    "#         path_segments = parsed_url.path.split('/')\n",
    "#         for segment in path_segments:\n",
    "#             if '3d' in segment and '4d' in segment:\n",
    "#                 # Extract latitude and longitude\n",
    "#                 parts = segment.split('!')\n",
    "#                 lat = next((p[2:] for p in parts if p.startswith('3d')), None)\n",
    "#                 lng = next((p[2:] for p in parts if p.startswith('4d')), None)\n",
    "#                 return lat, lng\n",
    "#         return None, None\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing URL {url}: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "# locations_df = populate_lat_long(locations_df[:5])\n",
    "# locations_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
